"""
Train Enhanced ML Model v2.1 - Weather & Track Condition Integration

Builds on ML v2.0 with additional weather and track condition modeling:
- All v2.0 features (track-specific models, ensemble learning, 70+ features)
- Weather data (temperature, humidity, rainfall, wind)
- Track condition effects (fast/slow/heavy ratings)
- Expected: 41-47% win rate (vs 40-45% v2.0)

Usage:
    python train_ml_enhanced.py

Output:
    - Enhanced model saved to models/greyhound_ml_v2.1_enhanced.pkl
    - Weather and track condition feature importance analysis
    - Performance metrics showing improvement over v2.0
"""

import sys
import os
sys.path.insert(0, os.path.dirname(__file__))

# Fix encoding for Windows console
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

from src.ml_predictor_advanced import AdvancedGreyhoundMLPredictor
from src.weather_track_data import WeatherTrackDataManager, create_sample_data_files
from src.ml_predictor import load_historical_data
import pandas as pd
import numpy as np
from datetime import datetime
import traceback
import logging

# Set up enhanced logging
log_file = "logs/train_ml_enhanced.log"
os.makedirs("logs", exist_ok=True)

# Configure logging to both file and console
# Use INFO level to avoid excessive DEBUG output from PDF parser libraries
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, mode='w', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

# Suppress DEBUG logging from PDF parsing libraries (pdfminer, etc.)
logging.getLogger('pdfminer').setLevel(logging.WARNING)
logging.getLogger('pdfplumber').setLevel(logging.WARNING)
logging.getLogger('PIL').setLevel(logging.WARNING)

# Set our logger to DEBUG for detailed training diagnostics
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

def log_exception(msg, exc_info=True):
    """Enhanced exception logging with full details"""
    logger.error(msg, exc_info=exc_info)
    if exc_info:
        print("\n" + "="*80)
        print("DETAILED ERROR INFORMATION:")
        print("="*80)
        traceback.print_exc()
        print("="*80 + "\n")

def integrate_weather_features(df, weather_manager):
    """
    Add weather and track condition features to race data.
    
    Args:
        df: DataFrame with race data (must have 'Date' and 'Track' columns)
        weather_manager: WeatherTrackDataManager instance
    
    Returns:
        DataFrame with additional weather/track condition features
    """
    try:
        if df is None or len(df) == 0:
            raise ValueError("CRITICAL ERROR: Empty or None DataFrame passed to integrate_weather_features")
        
        if weather_manager is None:
            raise ValueError("CRITICAL ERROR: weather_manager is None")
        
        weather_features = []
        
        for idx, row in df.iterrows():
            try:
                # Extract date and track with error checking
                race_date = row.get('Date', '2025-12-11')
                race_track = row.get('Track', 'Unknown')
                race_distance = row.get('Distance', 515)
                
                # Get condition features
                conditions = weather_manager.get_condition_features(
                    race_date, race_track, race_distance
                )
                
                weather_features.append(conditions)
            except Exception as e:
                print(f"‚ö†Ô∏è  WARNING: Error processing row {idx}: {e}")
                # Use default conditions on error
                weather_features.append({
                    'temperature_norm': 0.5,
                    'humidity_norm': 0.5,
                    'rainfall_norm': 0.0,
                    'wind_norm': 0.3,
                    'track_rating_norm': 1.0,
                    'ideal_conditions': 1,
                    'heat_stress_risk': 0,
                    'wet_track': 0
                })
        
        # Convert to DataFrame
        weather_df = pd.DataFrame(weather_features)
        
        # Select numeric features for ML
        weather_cols = [
            'temperature_norm',
            'humidity_norm',
            'rainfall_norm',
            'wind_norm',
            'track_rating_norm',
            'ideal_conditions',
            'heat_stress_risk',
            'wet_track'
        ]
        
        # Add to original DataFrame
        for col in weather_cols:
            if col in weather_df.columns:
                df[col] = weather_df[col].values
            else:
                print(f"‚ö†Ô∏è  WARNING: Weather feature '{col}' not found, using default value 0.5")
                df[col] = 0.5
        
        return df
    
    except Exception as e:
        print(f"‚ùå CRITICAL ERROR in integrate_weather_features: {e}")
        print(f"   DataFrame shape: {df.shape if df is not None else 'None'}")
        print(f"   DataFrame columns: {list(df.columns) if df is not None and hasattr(df, 'columns') else 'N/A'}")
        import traceback
        traceback.print_exc()
        raise

def main():
    print("=" * 80)
    print("üå§Ô∏è  ENHANCED ML TRAINING v2.1 - Weather & Track Condition Integration")
    print("=" * 80)
    print("\nEnhancements over v2.0:")
    print("  ‚úÖ Weather data integration (temperature, humidity, rainfall, wind)")
    print("  ‚úÖ Track condition modeling (fast/slow/heavy ratings)")
    print("  ‚úÖ 80+ total features (70+ from v2.0 + 10+ weather/track)")
    print("  ‚úÖ Expected: +1-2% win rate improvement")
    print("=" * 80)
    print(f"\nüìù DETAILED LOG FILE: {os.path.abspath(log_file)}")
    print("   All errors and diagnostics are being saved to this file for review")
    print("=" * 80)
    
    logger.info("="*80)
    logger.info("Enhanced ML Training v2.1 - Session Started")
    logger.info(f"Python version: {sys.version}")
    logger.info(f"Working directory: {os.getcwd()}")
    logger.info("="*80)
    
    # Step 1: Initialize weather/track data manager
    print("\nüå§Ô∏è  STEP 1: Initializing weather & track condition data...")
    print("-" * 80)
    
    try:
        # Create sample data files if they don't exist
        create_sample_data_files()
        
        weather_manager = WeatherTrackDataManager()
        print("‚úÖ Weather & track condition manager initialized")
        print(f"   Weather records: {len(weather_manager.weather_data)}")
        print(f"   Track condition records: {len(weather_manager.track_conditions)}")
        
        if len(weather_manager.weather_data) == 0:
            print("\nüìù NOTE: No weather data found - using seasonal inference")
            print("   To add actual weather data, edit data/weather_conditions.csv")
        
        if len(weather_manager.track_conditions) == 0:
            print("\nüìù NOTE: No track condition data found - using defaults")
            print("   To add track conditions, edit data/track_conditions.csv")
        
    except Exception as e:
        print(f"‚ùå Error initializing weather manager: {e}")
        print("Continuing with basic features only...")
        weather_manager = None
    
    # Step 2: Load historical data
    print("\nüìÅ STEP 2: Loading historical race data...")
    print("-" * 80)
    
    try:
        print("   Calling load_historical_data()...")
        # load_historical_data returns (race_data_list, winners_list)
        result = load_historical_data()
        
        # Detailed type checking and error reporting
        if result is None:
            print("‚ùå CRITICAL ERROR: load_historical_data() returned None")
            print("   Expected: (race_data_list, winners_list) tuple")
            return 1
        
        if not isinstance(result, tuple):
            print(f"‚ùå CRITICAL ERROR: load_historical_data() returned {type(result).__name__}, expected tuple")
            print(f"   Returned value: {result}")
            return 1
        
        if len(result) != 2:
            print(f"‚ùå CRITICAL ERROR: load_historical_data() returned tuple with {len(result)} elements, expected 2")
            print(f"   Expected: (race_data_list, winners_list)")
            return 1
        
        race_data_list, winners_list = result
        print(f"   ‚úì Successfully unpacked tuple: ({type(race_data_list).__name__}, {type(winners_list).__name__})")
        
        # Validate race_data_list
        if race_data_list is None:
            print("‚ùå CRITICAL ERROR: race_data_list is None")
            return 1
        
        if not isinstance(race_data_list, list):
            print(f"‚ùå CRITICAL ERROR: race_data_list is {type(race_data_list).__name__}, expected list")
            return 1
        
        if len(race_data_list) == 0:
            print("‚ùå ERROR: No historical data found (race_data_list is empty)")
            print("   Please ensure you have:")
            print("   1. Race PDFs in data/ folder")
            print("   2. Results CSVs in data/ folder (results_YYYY-MM-DD.csv)")
            print("\nüîç DIAGNOSTIC INFO:")
            print(f"   Data directory: {os.path.abspath('data')}")
            print(f"   Directory exists: {os.path.exists('data')}")
            if os.path.exists('data'):
                csv_files = [f for f in os.listdir('data') if f.endswith('.csv') and f.startswith('results_')]
                print(f"   Results CSV files found: {len(csv_files)}")
                if csv_files:
                    print(f"   CSV files: {csv_files[:5]}")
            return 1
        
        print(f"‚úÖ Loaded historical data:")
        print(f"   Total races: {len(race_data_list)}")
        
        # Calculate total dogs with error handling
        try:
            total_dogs = sum(len(race_df) if race_df is not None else 0 for race_df in race_data_list)
            print(f"   Total dogs: {total_dogs}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Could not calculate total dogs: {e}")
        
        # Check how many races could potentially be added
        import glob
        results_files_check = glob.glob("data/results_*.csv")
        if results_files_check:
            total_results_check = 0
            for rf in results_files_check:
                try:
                    df_r = pd.read_csv(rf)
                    total_results_check += len(df_r)
                except:
                    pass
            
            if total_results_check > len(race_data_list):
                missing_pdfs = total_results_check - len(race_data_list)
                print(f"\nüìä DATA AVAILABILITY:")
                print(f"   Results available: {total_results_check} races")
                print(f"   PDFs available: {len(race_data_list)} races")
                print(f"   Missing PDFs: {missing_pdfs} races ({missing_pdfs/total_results_check*100:.1f}%)")
                print(f"\nüí° NOTE: Training uses only races with BOTH PDF + results")
                print(f"   To train on all {total_results_check} races, add the missing {missing_pdfs} PDFs to data/ folder")
        
        # Sample first race for diagnostics
        if len(race_data_list) > 0:
            first_race = race_data_list[0]
            print(f"\nüîç DIAGNOSTIC - First race info:")
            print(f"   Type: {type(first_race).__name__}")
            if hasattr(first_race, 'shape'):
                print(f"   Shape: {first_race.shape}")
            if hasattr(first_race, 'columns'):
                print(f"   Columns ({len(first_race.columns)}): {list(first_race.columns)[:10]}")
                if len(first_race.columns) > 10:
                    print(f"            ... and {len(first_race.columns) - 10} more")
        
        # Get date range from first and last race DataFrames if available
        if len(race_data_list) > 0 and hasattr(race_data_list[0], 'columns') and 'Date' in race_data_list[0].columns:
            try:
                all_dates = []
                for race_df in race_data_list:
                    if race_df is not None and hasattr(race_df, 'columns') and 'Date' in race_df.columns:
                        all_dates.extend(race_df['Date'].tolist())
                if all_dates:
                    all_dates = pd.Series(all_dates)
                    print(f"   Date range: {all_dates.min()} to {all_dates.max()}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Could not determine date range: {e}")
        
    except Exception as e:
        print(f"‚ùå CRITICAL ERROR loading historical data: {e}")
        print(f"   Error type: {type(e).__name__}")
        print(f"   Error details: {str(e)}")
        import traceback
        print("\nüìã FULL TRACEBACK:")
        traceback.print_exc()
        return 1
    
    # Step 3: Integrate weather/track condition features
    if weather_manager:
        print("\nüå§Ô∏è  STEP 3: Integrating weather & track condition features...")
        print("-" * 80)
        
        try:
            print(f"   Processing {len(race_data_list)} races...")
            # Apply weather features to each race DataFrame in the list
            race_data_list_enhanced = []
            errors_count = 0
            
            for i, race_df in enumerate(race_data_list):
                try:
                    if race_df is None:
                        print(f"‚ö†Ô∏è  WARNING: Race {i+1} is None, skipping")
                        errors_count += 1
                        continue
                    
                    race_df_enhanced = integrate_weather_features(race_df, weather_manager)
                    race_data_list_enhanced.append(race_df_enhanced)
                    
                    # Progress indicator every 50 races
                    if (i + 1) % 50 == 0:
                        print(f"   ... processed {i+1}/{len(race_data_list)} races")
                    
                except Exception as e:
                    print(f"‚ùå ERROR processing race {i+1}: {e}")
                    errors_count += 1
                    # Continue with original race data
                    race_data_list_enhanced.append(race_df)
            
            if errors_count > 0:
                print(f"‚ö†Ô∏è  {errors_count} races had errors during weather integration")
            
            race_data_list = race_data_list_enhanced
            
            print(f"‚úÖ Weather/track features added to {len(race_data_list)} races")
            print(f"   Successfully processed: {len(race_data_list) - errors_count}/{len(race_data_list)}")
            print(f"   Total features now: 80+")
            
            # Show sample of new features from first race
            if len(race_data_list) > 0 and race_data_list[0] is not None:
                try:
                    weather_feature_cols = [col for col in race_data_list[0].columns 
                                           if any(x in col.lower() for x in ['temperature', 'humidity', 'rainfall', 'wind', 'track_rating', 'ideal', 'heat', 'wet'])]
                    
                    if weather_feature_cols:
                        print(f"   New weather/track features: {len(weather_feature_cols)}")
                        for col in weather_feature_cols[:5]:  # Show first 5
                            print(f"     - {col}")
                        if len(weather_feature_cols) > 5:
                            print(f"     ... and {len(weather_feature_cols) - 5} more")
                    else:
                        print("   ‚ö†Ô∏è  No weather features found in processed data")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è  Could not display weather features: {e}")
            
        except Exception as e:
            print(f"‚ùå CRITICAL ERROR: Could not integrate weather features: {e}")
            print(f"   Error type: {type(e).__name__}")
            print("   Continuing with ML v2.0 features only")
            import traceback
            print("\nüìã FULL TRACEBACK:")
            traceback.print_exc()
    else:
        print("\n‚ö†Ô∏è  STEP 3: Skipping weather integration (manager not available)")
        print("   Training with ML v2.0 features only")
    
    # Step 4: Train enhanced model
    print("\nü§ñ STEP 4: Training enhanced ML model...")
    print("-" * 80)
    print("This may take 10-20 minutes...")
    print()
    
    try:
        # Pre-training validation
        print("üîç PRE-TRAINING VALIDATION:")
        print(f"   race_data_list type: {type(race_data_list).__name__}")
        print(f"   race_data_list length: {len(race_data_list) if race_data_list else 'N/A'}")
        print(f"   winners_list type: {type(winners_list).__name__}")
        print(f"   winners_list length: {len(winners_list) if winners_list else 'N/A'}")
        
        if len(race_data_list) < 100:
            print(f"\n‚ö†Ô∏è  WARNING: Only {len(race_data_list)} races available for training")
            print("   Recommended minimum: 100 races")
            print("   This may result in poor model performance")
            response = input("   Continue anyway? (y/n): ")
            if response.lower() != 'y':
                print("   Training cancelled by user")
                return 1
        
        # Initialize predictor (will use enhanced features)
        print("\n   Initializing AdvancedGreyhoundMLPredictor...")
        predictor = AdvancedGreyhoundMLPredictor()
        print("   ‚úì Predictor initialized successfully")
        
        # Verify method exists
        if not hasattr(predictor, 'train_track_specific'):
            print(f"\n‚ùå CRITICAL ERROR: AdvancedGreyhoundMLPredictor does not have 'train_track_specific' method")
            print(f"   Available methods: {[m for m in dir(predictor) if not m.startswith('_') and callable(getattr(predictor, m))]}")
            return 1
        
        print(f"   ‚úì Method 'train_track_specific' found")
        print("\n   Starting training process...")
        
        # Train with enhanced data (race_data_list and winners_list)
        try:
            logger.info(f"Calling train_track_specific with {len(race_data_list)} races and {len(winners_list)} winners")
            predictor.train_track_specific(race_data_list, winners_list)
            logger.info("Training completed successfully")
        except Exception as train_error:
            logger.error(f"Error during train_track_specific execution: {train_error}")
            logger.error(f"Error occurred at line: {train_error.__traceback__.tb_lineno if train_error.__traceback__ else 'unknown'}")
            raise  # Re-raise to be caught by outer exception handlers
        
        print("\n‚úÖ Enhanced model training complete!")
        logger.info("Enhanced model training complete!")
        
    except AttributeError as e:
        error_msg = f"ATTRIBUTE ERROR during training: {e}"
        print(f"\n‚ùå {error_msg}")
        logger.error(error_msg)
        print(f"   This typically means a method or attribute doesn't exist")
        print(f"   Predictor type: {type(predictor).__name__}")
        print(f"   Available methods: {[m for m in dir(predictor) if not m.startswith('_') and callable(getattr(predictor, m))]}")
        log_exception("AttributeError details:")
        
        # Additional diagnostic info
        logger.debug(f"Predictor class: {predictor.__class__.__module__}.{predictor.__class__.__name__}")
        logger.debug(f"Predictor MRO: {[c.__name__ for c in predictor.__class__.__mro__]}")
        return 1
        
    except TypeError as e:
        error_msg = f"TYPE ERROR during training: {e}"
        print(f"\n‚ùå {error_msg}")
        logger.error(error_msg)
        print(f"   This typically means wrong argument types were passed")
        print(f"   race_data_list type: {type(race_data_list).__name__}")
        print(f"   winners_list type: {type(winners_list).__name__}")
        
        # Sample data types for debugging
        if race_data_list:
            logger.debug(f"First race type: {type(race_data_list[0])}")
            logger.debug(f"First race shape: {race_data_list[0].shape if hasattr(race_data_list[0], 'shape') else 'N/A'}")
        if winners_list:
            logger.debug(f"First winner type: {type(winners_list[0])}")
            logger.debug(f"First winner value: {winners_list[0]}")
        
        log_exception("TypeError details:")
        return 1
        
    except ValueError as e:
        error_msg = f"VALUE ERROR during training: {e}"
        print(f"\n‚ùå {error_msg}")
        logger.error(error_msg)
        print(f"   This typically means invalid data values")
        
        # Log data statistics
        logger.debug(f"Race data list length: {len(race_data_list)}")
        logger.debug(f"Winners list length: {len(winners_list)}")
        if race_data_list:
            try:
                dogs_per_race = [len(race) for race in race_data_list if race is not None]
                logger.debug(f"Dogs per race stats - min: {min(dogs_per_race)}, max: {max(dogs_per_race)}, avg: {sum(dogs_per_race)/len(dogs_per_race):.1f}")
            except:
                pass
        
        log_exception("ValueError details:")
        return 1
        
    except KeyError as e:
        error_msg = f"KEY ERROR during training: {e}"
        print(f"\n‚ùå {error_msg}")
        logger.error(error_msg)
        print(f"   This means a required column/key is missing from the data")
        
        # Log available columns
        if race_data_list and len(race_data_list) > 0:
            first_race = race_data_list[0]
            if hasattr(first_race, 'columns'):
                logger.debug(f"Available columns in first race: {list(first_race.columns)}")
        
        log_exception("KeyError details:")
        return 1
        
    except MemoryError as e:
        error_msg = f"MEMORY ERROR during training: {e}"
        print(f"\n‚ùå {error_msg}")
        logger.error(error_msg)
        print(f"   System ran out of memory. Try:")
        print(f"   1. Close other applications")
        print(f"   2. Reduce training data size")
        print(f"   3. Use a machine with more RAM")
        log_exception("MemoryError details:")
        return 1
        
    except Exception as e:
        error_msg = f"UNEXPECTED ERROR during training: {type(e).__name__}: {e}"
        print(f"\n‚ùå {error_msg}")
        logger.error(error_msg)
        print(f"   Error type: {type(e).__name__}")
        print(f"   Error message: {str(e)}")
        
        # Get detailed error info
        exc_type, exc_value, exc_tb = sys.exc_info()
        if exc_tb:
            logger.error(f"   Error at file: {exc_tb.tb_frame.f_code.co_filename}")
            logger.error(f"   Error at line: {exc_tb.tb_lineno}")
            logger.error(f"   Error in function: {exc_tb.tb_frame.f_code.co_name}")
        
        log_exception("Unexpected error details:")
        return 1
    
    # Step 5: Save enhanced model
    print("\nüíæ STEP 5: Saving enhanced model...")
    print("-" * 80)
    
    model_path = "models/greyhound_ml_v2.1_enhanced.pkl"
    
    try:
        # Ensure models directory exists
        models_dir = os.path.dirname(model_path)
        if not os.path.exists(models_dir):
            print(f"   Creating directory: {models_dir}")
            os.makedirs(models_dir, exist_ok=True)
        
        # Verify save_model method exists
        if not hasattr(predictor, 'save_model'):
            print(f"‚ùå CRITICAL ERROR: Predictor does not have 'save_model' method")
            print(f"   Available methods: {[m for m in dir(predictor) if not m.startswith('_') and callable(getattr(predictor, m))]}")
            return 1
        
        print(f"   Saving to: {os.path.abspath(model_path)}")
        predictor.save_model(model_path)
        
        # Verify file was created
        if not os.path.exists(model_path):
            print(f"‚ùå ERROR: Model file was not created at {model_path}")
            return 1
        
        file_size_mb = os.path.getsize(model_path) / 1024 / 1024
        print(f"‚úÖ Model saved successfully!")
        print(f"   Location: {os.path.abspath(model_path)}")
        print(f"   File size: {file_size_mb:.2f} MB")
        
    except Exception as e:
        print(f"‚ùå ERROR saving model: {e}")
        print(f"   Error type: {type(e).__name__}")
        print(f"   Model path: {os.path.abspath(model_path)}")
        import traceback
        print("\nüìã FULL TRACEBACK:")
        traceback.print_exc()
        return 1
    
    # Step 6: Summary and next steps
    print("\n" + "=" * 80)
    print("‚úÖ ENHANCED ML MODEL v2.1 TRAINING COMPLETE!")
    print("=" * 80)
    
    logger.info("="*80)
    logger.info("Enhanced ML Model v2.1 Training - COMPLETED SUCCESSFULLY")
    logger.info("="*80)
    
    print("\nüìä MODEL SUMMARY:")
    print(f"   Version: ML v2.1 Enhanced (Weather & Track Conditions)")
    print(f"   Training data: {len(race_data_list)} races")
    print(f"   Track-specific models: {len(predictor.track_models)}")
    print(f"   Total features: 80+ (70+ ML + 10+ weather/track)")
    print(f"   Ensemble algorithms: 2-4 (RF, GB, XGB, LGB - if available)")
    
    logger.info(f"Training data: {len(race_data_list)} races")
    logger.info(f"Track-specific models: {len(predictor.track_models)}")
    logger.info(f"Model saved to: {os.path.abspath(model_path)}")
    
    print("\nüéØ EXPECTED PERFORMANCE:")
    print(f"   Win rate: 41-47% (hybrid picks)")
    print(f"   Improvement over v2.0: +1-2%")
    print(f"   Selectivity: ~6-8% of races")
    
    print("\n" + "=" * 80)
    print("üìã DATA COVERAGE ANALYSIS")
    print("=" * 80)
    
    # Analyze which races have PDFs vs results only
    import glob
    pdf_files = glob.glob("data/*form.pdf")
    results_files = glob.glob("data/results_*.csv")
    
    # Count total results
    total_results = 0
    for results_file in results_files:
        df_results = pd.read_csv(results_file)
        total_results += len(df_results)
    
    print(f"\nüìÅ Data Files Found:")
    print(f"   PDFs: {len(pdf_files)}")
    print(f"   Results CSVs: {len(results_files)}")
    print(f"   Total race results: {total_results}")
    print(f"   Races with BOTH PDF + results: {len(race_data_list)}")
    print(f"   Missing PDFs for: {total_results - len(race_data_list)} races")
    
    if total_results - len(race_data_list) > 0:
        print(f"\nüí° TO GET MORE TRAINING DATA:")
        print(f"   Add the missing {total_results - len(race_data_list)} race PDFs to data/ folder")
        print(f"   This will increase training accuracy and model robustness")
        print(f"   Currently using: {len(race_data_list)}/{total_results} ({len(race_data_list)/total_results*100:.1f}%) of available races")
    
    print("\n" + "=" * 80)
    print("üìù NEXT STEPS TO GENERATE BETTING REPORTS")
    print("=" * 80)
    print("\n‚ö†Ô∏è  IMPORTANT: Training only creates the model - it does NOT generate Excel reports!")
    print("\nTo generate betting picks and Excel reports:")
    print("\n1Ô∏è‚É£  Place today's race PDFs in data_predictions/ folder")
    print("   Example: data_predictions/SANDOWN_12DEC_form.pdf")
    
    print("\n2Ô∏è‚É£  Run predictions using ONE of these methods:")
    print("   Option A: python run_ml_hybrid_enhanced.py")
    print("   Option B: Double-click run_ml_hybrid_enhanced.bat (Windows)")
    
    print("\n3Ô∏è‚É£  Check outputs/ folder for Excel files:")
    print("   ‚Ä¢ ml_hybrid_enhanced_picks.xlsx - High-confidence bets")
    print("   ‚Ä¢ ml_enhanced_all_predictions.xlsx - All predictions ranked")
    print("   ‚Ä¢ v44_picks_comparison.csv - Baseline v4.4 picks")
    
    print("\nüí° TO IMPROVE ACCURACY FURTHER:")
    print("   ‚Ä¢ Add actual weather data to data/weather_conditions.csv")
    print("   ‚Ä¢ Add track conditions to data/track_conditions.csv")
    print("   ‚Ä¢ Add {0} missing race PDFs to data/ folder".format(total_results - len(race_data_list)) if total_results > len(race_data_list) else "   ‚Ä¢ Collect more historical race PDFs")
    print("   ‚Ä¢ Update weather data daily for maximum accuracy")
    
    print("\n" + "=" * 80)
    print("üéâ TRAINING SUCCESSFUL! Model ready for predictions.")
    print("=" * 80)
    print(f"\n‚úÖ Model saved to: {os.path.abspath(model_path)}")
    print(f"‚úÖ Run predictions to generate Excel betting reports")
    print(f"\nüìù DETAILED LOG SAVED TO: {os.path.abspath(log_file)}")
    print("   Review this file for complete training details and diagnostics")
    print("   If you encounter any issues, share this log file for debugging")
    
    logger.info("="*80)
    logger.info("Training session completed successfully")
    logger.info(f"Log file saved to: {os.path.abspath(log_file)}")
    logger.info("="*80)
    
    return 0

if __name__ == "__main__":
    try:
        exit_code = main()
        if exit_code != 0:
            print(f"\n‚ùå TRAINING FAILED WITH EXIT CODE: {exit_code}")
            print(f"üìù CHECK LOG FILE FOR DETAILS: {os.path.abspath(log_file)}")
            logger.error(f"Training failed with exit code: {exit_code}")
        exit(exit_code)
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Training interrupted by user (Ctrl+C)")
        logger.warning("Training interrupted by user")
        print(f"üìù Partial log saved to: {os.path.abspath(log_file)}")
        exit(130)
    except Exception as e:
        print(f"\n\n‚ùå CRITICAL UNHANDLED ERROR: {e}")
        log_exception("Critical unhandled error in main:", exc_info=True)
        print(f"\nüìù FULL ERROR LOG SAVED TO: {os.path.abspath(log_file)}")
        print("   Please review this file for complete error details")
        exit(1)
